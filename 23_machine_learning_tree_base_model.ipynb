{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree(CART : Classification and Regression Tree)\n",
    "> **`Decision Tree`** 모델은 **예측/분류가 모두 가능**한 **지도학습** 머신러닝 모델이다.   \n",
    "스무고개 게임을 하듯 여러 개의 가정을 데이터에 반영하고 이를 바탕으로 결정경계(decision boundary)를 생성  \n",
    "모델 예측 및 분류 결과에 따른 해석이 굉장히 용이하여 **모델 해석이 필요한 문제에 사용**한다.ex)신용평가, 모델분류  \n",
    "최근에는 `Decision Tree`모델을 베이스로 한 부스팅 트리 모델(**`Xgboost`**, **`LightGBM`**, **`Catboost`**)등으로 데이터분석 대회 수상을 하면서 실무 적용 케이스가 많아졌다.\n",
    "\n",
    "### 모델구조\n",
    "> 뿌리 노드(root node) : 최상위 노드, 모든 샘플 포함  \n",
    "잎 노드(leaf node) : 최하위 노드, 여기에 속한 샘플이 어떤 클래스인지 결정 됨  \n",
    "노드(node) : 뿌리 노드와 잎 노드 사이에 있는 노드  \n",
    "가지(branch) : 노드를 나누는 기준  \n",
    "깊이(depth) : 뿌리 노드와 잎 노드 까지의 노드 갯수\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1gTRvBWaKpbR5VI9Iv1_OlwKg4YQGPxXr\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습\n",
    "#### 불순도\n",
    "> `Decision Tree` 모델을 학습시키는 방법  \n",
    "정보화 이론에서 사용하는 Gini 계수와 엔트로피를 사용한다.  \n",
    "불순도가 0.5에 가까수록 불순도가 높고 0에 가까울 수록 순도가 높다.  \n",
    "즉, 한 노드의 불순도가 가능한 많이 떨어지도록(순도가 올라가도록) 노드를 나눈다.\n",
    "\n",
    "$$ Gini = 1 - \\sum_1^n{(p_i)^2} $$\n",
    "\n",
    "$$ Entropy = - \\sum_1^n{p_iln(p_i)} $$\n",
    "\n",
    "#### Gini index\n",
    "위 예시에서 뿌리 노드 기준 지니계수 계산법  \n",
    "class1 : 삼각형  \n",
    "class2 : 동그라미  \n",
    ">X < 0\n",
    ">> True = class1 3개, class2 4개  \n",
    "$1 - ({3 \\over 3+4})^2 - ({4 \\over 3+4})^2 = 0.48$  \n",
    "False = class1 4개, class2 3개  \n",
    "$1 - ({4 \\over 4+3})^2 - ({3 \\over 4+3})^2 = 0.48$  \n",
    "total Gini 계수  \n",
    "$1 - ({7 \\over 7+7})0.48 - ({7 \\over 7+7})0.48 = 0.52$\n",
    "\n",
    "위 예시에서 잎 노드 기준 지니계수 계산법  \n",
    "class1 : 삼각형  \n",
    "class2 : 동그라미  \n",
    ">Y < 1\n",
    ">> True = class1 3개, class2 0개  \n",
    "$1 - ({3 \\over 3})^2 - ({0 \\over 3})^2 = 0$  \n",
    "False = class1 0개, class2 4개  \n",
    "$1 - ({0 \\over 4})^2 - ({4 \\over 4})^2 = 0$  \n",
    "total Gini 계수  \n",
    "$1 - ({4 \\over 4+3})0 - ({3 \\over 4+3})0 = 0$\n",
    "\n",
    "위의 예시에서는 최적화 과정을 거치지 않은 결정경계를 생성했지만 실제 알고리즘은 각 분지 기준에 대한 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree classifier 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T18:54:38.051914Z",
     "start_time": "2021-07-23T18:54:38.048755Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요모듈 import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:14:48.262984Z",
     "start_time": "2021-07-23T05:14:48.257281Z"
    }
   },
   "outputs": [],
   "source": [
    "# iris 데이터로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:14:48.613957Z",
     "start_time": "2021-07-23T05:14:48.610037Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 설명\n",
    "# sklearn dataset의 iris 데이터 사용\n",
    "# 붓꽃의 꽃받침 길이/넓이, 꽃잎의 길이/넓이를 변수로 가진 붓꽃의 종류 구분 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:14:49.319422Z",
     "start_time": "2021-07-23T05:14:49.314659Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:14:50.811729Z",
     "start_time": "2021-07-23T05:14:50.808605Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:14:51.084196Z",
     "start_time": "2021-07-23T05:14:51.080458Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:14:51.575862Z",
     "start_time": "2021-07-23T05:14:51.570525Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:15:00.981391Z",
     "start_time": "2021-07-23T05:15:00.977962Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:15:07.165097Z",
     "start_time": "2021-07-23T05:15:07.160977Z"
    }
   },
   "outputs": [],
   "source": [
    "# test셋 분류 결과 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:15:18.316554Z",
     "start_time": "2021-07-23T05:15:18.305504Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가지표 출력\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance\n",
    "트리 기반 모델은 트리를 분기하는 과정에서 어떤 변수가 모델을 학습하는데 중요한지 살펴볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:15:29.329957Z",
     "start_time": "2021-07-23T05:15:29.192963Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature importance 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:15:41.340291Z",
     "start_time": "2021-07-23T05:15:40.664546Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가지치기 (pruning)\n",
    ">`Decision Tree`모델은 모든 **잎 노드의 불순도가 0이 되는 순간까지 모델을 성장**시키면서 크기를 키워나간다.  \n",
    "순수 노드로만 이루어진 트리 모델은 훈련 데이터를 100% 정확도로 맞출 수 있다.  \n",
    "이러한 특성 때문에 트리 모델은 **과적합에 취약**하다.  \n",
    "과적합 방지를 위해서는 **트리의 복잡도를 제어** 할 필요가 있다.\n",
    "\n",
    ">과적합 방지를 위한 모델링 파라메터  \n",
    ">> - **`max_depth`** : 트리의 최대 깊이  \n",
    "- `max_leaf_nodes` : 잎 노드의 최대개수  \n",
    "- `min_sample_leaf` : 잎 노드가 되기 위한 최소 샘플 갯수  \n",
    "- `min_sample_split` : 잎 노드가 분지 되기 위한 최소 샘플 갯수\n",
    "\n",
    "위의 iris 데이터는 3개의 클래스로 이루어진 데이터셋이지만 모델플로팅 결과 2뎁스의 노드에서 어느정도 데이터 구분이 되었습니다.  \n",
    "이를 기준으로 사후 가지치기를 진행 해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree regressor\n",
    "> `Decision Tree`모델은 알고리즘 특성으로 분류 및 예측 모델링에 모두 사용이 가능하다.  \n",
    "일반적으로 잎 노드에 속한 학습샘플의 값의 평균을 바탕으로 예측값을 결정한다.  \n",
    "회귀모델 평가 방법인 MSE를 각 노드에 속한 샘플에 적용하고 이를 최소화 시킨다.  \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1VNT8MulVBhqDLj0tVTRrf8s-8EIv5RZP\">\n",
    "<img src=\"https://drive.google.com/uc?id=1ICIKUdPHbx9ZkBSKzOgl7248QaIQrq2U\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regressor 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:17:40.011554Z",
     "start_time": "2021-07-23T05:17:39.989338Z"
    }
   },
   "outputs": [],
   "source": [
    "# 보스턴 집값 데이터 로딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:17:40.266531Z",
     "start_time": "2021-07-23T05:17:40.260697Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "\n",
    "# 훈련셋과 테스트셋 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:37:56.611368Z",
     "start_time": "2021-07-23T05:37:56.608375Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:37:57.423807Z",
     "start_time": "2021-07-23T05:37:57.414282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:37:57.663605Z",
     "start_time": "2021-07-23T05:37:57.659049Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:37:57.964589Z",
     "start_time": "2021-07-23T05:37:57.957488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score : 81.5325\n",
      "RMSE score : 3.5961\n",
      "MAE score : 2.8205\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가지표 출력\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:37:59.218942Z",
     "start_time": "2021-07-23T05:37:59.022560Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T06:30:12.192008Z",
     "start_time": "2021-07-23T06:30:12.189331Z"
    }
   },
   "source": [
    "## Random Forest\n",
    ">**`Random forest`** 는 **`Decision Tree`** 모델의 **모형 결합(ensemble)방법론**  \n",
    "\n",
    "### ensemble(앙상블)\n",
    "> **복수의 예측 모형을 결합**하여 더 나은 성능의 예측을 하려는 시도이다.  \n",
    "단일 모형을 사용할 때 보다 **성능 분산이 감소**하고, 즉 **과적합을 방지**한다.  \n",
    "개별 모형이 성능이 안좋을 경우에는 결합 모형의 성능이 더 향상된다.  \n",
    "앙상블 방법론에는 **배깅**, **부스팅**, **스태킹**이 있다.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1JJVUyYwHD2ddpigy0D3mG5KFLc5Yq1qR\">\n",
    "\n",
    "### bagging(배깅) : Bootstrap Aggregating\n",
    "> **복원 추출**로 여러개의 sub sample 데이터셋을 만든다.  \n",
    "각각의 데이터셋을 개별 모델에 학습시켜 서로 다른 결과를 얻는다.  \n",
    "투표법 혹은 평균법을 사용하여 개별 모델 결과를 바탕으로 최종 추정치를 얻는다.  \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1CMsFhLTApJqrOlGdqVE4qWH89j04w_xF\">\n",
    "\n",
    "### Random Forest bootstrap\n",
    "> 복원 추출 된 sub sample 에서 랜덤으로 feature를 선택하여 모델 학습에 사용한다.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1MfkxFwIsQJgjT_VD_CFl_fM3WJfc_3BG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ramdom Forest 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:27:51.350155Z",
     "start_time": "2021-07-23T07:27:51.347475Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합 방지를 위한 모델링 파라메터  \n",
    "> - **n_estimators** : 사용 할 트리 모델 갯수  \n",
    "- **max_depth** : 트리의 최대 깊이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:28:25.911038Z",
     "start_time": "2021-07-23T07:28:25.908078Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:28:35.922554Z",
     "start_time": "2021-07-23T07:28:35.667634Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:29:05.088757Z",
     "start_time": "2021-07-23T07:29:05.074728Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:29:26.512950Z",
     "start_time": "2021-07-23T07:29:26.506313Z"
    }
   },
   "outputs": [],
   "source": [
    "# 평가\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Tree\n",
    "> 배깅과 부스팅의 차이점은 학습을 위해 사용하는 개별모델을 병렬/직렬로 구성함에 있다.  \n",
    "배깅의 경우 sub sample에 따라 개별 모델을 모두 학습시키고 결과를 투표 혹은 평균을 내어 예측한다면  \n",
    "부스팅은 **개별 모델의 학습을 순차적**으로 시키며 이전 개별 모델의 결과 중 **오분류 된 데이터 혹은 오차에 가중치 부여**  \n",
    "초기에는 동일 가중치를 갖지만 각 학습 과정을 거치며 복원 추출 시 가중치의 분포/이전 round의 오차를 고려  \n",
    "\n",
    ">> 해당모델에는 `Adaboost`, `GBM`, `Xgboost`, `lightGBM`, `catboost`가 있다.\n",
    "\n",
    "### bagging 과 boosting\n",
    "<img src=\"https://drive.google.com/uc?id=1rhB9YkRkKILRb0GqOfa99K-EQ7CEcrPc\">\n",
    "\n",
    "### Adaptive booting(Adaboost)\n",
    "> a -> f 순서로 학습이 진행 되고 있다. 각 학습 단계(round)에서 오분류 된 데이터에 가중치를 부여하고  \n",
    "다음 라운드에서 가중치가 부여 된 데이터를 잘 맞추기 위한 개별모델이 학습 된다.  \n",
    "최종 모델은 개별 모델의 결과가 합쳐져서 최종 모델링이 된다.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1VKmbttZT4aPOAaYuqhw2os7nFMOs6MMJ\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient boost\n",
    "이전 round 모델의 데이터별 오류를 학습하는 모델을 사용하여 점진적으로 총 모델링 오차를 줄이는 부스팅 방법\n",
    "\n",
    "$$y = h_0(x) + error_0 $$\n",
    "$$error_0 = h_1(x) + error_1 $$\n",
    "$$error_1 = h_2(x) + error_2 $$\n",
    "$$\\vdots$$\n",
    "$$y = h_0(x) + h_1(x) + h_2(x) + \\cdots + small error $$\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1Ty-CEINGgXuHtghd0GuDsxO1CfWahDYB\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost\n",
    "> 머신러닝 알고리즘 대회인 kaggle, KDD cup등에서 우승을 한 팀들이 xgboost를 많이 활용한 것이 알려지면서 주목받음.  \n",
    "boosting 모델에서 오류를 학습하여 다음 round에 반영시키는 것은 gadient boosting과 큰 차이가 없음.  \n",
    "다만, 학습을 위한 비용함수에 규제화 식이 추가되어 모델이 과적합 되는 것을 방지함.  \n",
    "규제화를 통해 복잡한 모델에 패널티를 부여  \n",
    "\n",
    "$$obj^{(t)} = \\sum_1^{n} l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^t \\Omega(f_i) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설치\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T18:54:13.219885Z",
     "start_time": "2021-07-23T18:54:13.217404Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:11:37.706499Z",
     "start_time": "2021-07-23T19:11:37.685483Z"
    }
   },
   "outputs": [],
   "source": [
    "# 보스턴 데이터 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:11:40.103931Z",
     "start_time": "2021-07-23T19:11:40.100867Z"
    }
   },
   "outputs": [],
   "source": [
    "# 타겟 데이터 분할\n",
    "\n",
    "# 테스트셋 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:12:00.134845Z",
     "start_time": "2021-07-23T19:12:00.131855Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "\n",
    "'''\n",
    "xbgoost 주요 파라메터\n",
    "XGBRegressor(\n",
    "    max_depth=3, 트리의 최대 깊이\n",
    "    learning_rate=0.1, 학습률 학습 round별로 가중치를 얼만큼 사용할 것인지 0.01 ~ 0.2 사용\n",
    "    n_estimators=100, 나무 갯수\n",
    "    verbosity=1, \n",
    "    silent=None, 동작메세지 프린트 여부 0, 1\n",
    "    objective='reg:linear', 비용함수 reg:squarederror, binary:logistic, multi:softmax\n",
    "    booster='gbtree', gbtree:트리모델, gblinear:선형모델\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain',\n",
    "    **kwargs,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:12:00.341670Z",
     "start_time": "2021-07-23T19:12:00.297797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(objective='reg:squarederror')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:12:01.383393Z",
     "start_time": "2021-07-23T19:12:01.379362Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:12:02.729515Z",
     "start_time": "2021-07-23T19:12:02.722063Z"
    }
   },
   "outputs": [],
   "source": [
    "# 평가지표 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T19:12:04.120476Z",
     "start_time": "2021-07-23T19:12:03.883701Z"
    }
   },
   "outputs": [],
   "source": [
    "# 변수 중요도 출력\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
