{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network(deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T11:25:00.784158Z",
     "start_time": "2021-07-30T11:24:59.903955Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network(인공신경망)\n",
    "> **Neural network**는 사람의 신경을 본따 만든 머신러닝 알고리즘이다.  \n",
    "종속변수가 있어야 하는 **지도학습** 모델이며 출력 구분에 따라 **예측/분류 문제에 모두 사용**이 가능하다.  \n",
    "기존 선형회귀/로지스틱회귀 뿐 아니라 훨씬 더 복잡한 다차원의 비선형성 모델까지 표현이 가능하다.  \n",
    ">> `DNN`, `RNN`, `CNN`, `LSTM`을 기본으로 한 수 많은 네트워크 구조가 지속적으로 연구되고 있다.  \n",
    "이미지 처리에 `CNN`, 자연어 처리에 `LSTM`을 기본구조로 많이 사용  \n",
    "최근에는 데이터에 따른 기본구조를 따르지 않고 모델 전환에 관한 연구가 진행되고 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본적인 구조\n",
    ">기본적인 신경망의 layer 단위로 구성이 되는데 기본적인 구조는 아래와 같다.  \n",
    ">> **input layer** : **설명변수(X)**를 받아들이는(저장)하는 레이어  \n",
    "**hidden layer** : 연산 layer, **input과 output layer를 제외 한 모든 layer**는 hidden layer이다.  \n",
    "**output layer** : 출력 layer, 목적식 혹은 **예측/분류에 따라 출력 layer를 다르게** 설정하여 모델링.  \n",
    "**node** : layer에 포함 된 동그라미 하나  \n",
    "**weight(가중치)** : node 와 node간 연결되어 있는 회색 화살표  \n",
    "<img src=\"https://drive.google.com/uc?id=1qjjXfWEPnVVnD_rwqHsq8enC9Vgzyggm\">\n",
    "\n",
    "#### 선형결합 함수\n",
    "# $$ z = w^Tx + b $$\n",
    "> hidden layer에 도달하는 값은 결국 X와 w의 선형 함수식으로 나타낼 수 있으며 벡터/매트릭스 연산으로 계산한다.  \n",
    ">><img src=\"https://drive.google.com/uc?id=1NRXuxc1qx_EwIZ9A63_JAkKD6uSpivHb\">\n",
    "\n",
    "\n",
    "#### perceptron(퍼셉트론)\n",
    "# $$ \\hat{y} = g(\\sum_{i=1}^m x_iw_i)$$\n",
    "> 인공신경망의 가장 기본이 되는 단위.  \n",
    "위의 기본적인 신경망 구조에서 hidden layer의 노드 하나에 대한 자세한 구조를 살펴본다면 아래와 같은 구조를 갖는다.  \n",
    "각 노드의 선형 함수의 합에 비선형 **활성함수 g(activation function)를 적용**하여 비선형 변환을 만든다.  \n",
    ">><img src=\"https://drive.google.com/uc?id=1-KcMMdqfEHYwPeDuGQQ5623VAvp7oxXm\">\n",
    "\n",
    "#### activation function(활성화함수)\n",
    "> 노드의 선형식 결과를 비선형 출력결과로 만들어주는 함수  \n",
    "딥러닝 강의가 아니기에 각 함수별 특징은 참고링크를 확인해주세요  \n",
    "https://deepinsight.tistory.com/113\n",
    ">><img src=\"https://drive.google.com/uc?id=1G95TtpGcYZ75-P4tjSX3EzpP6hfi5loO\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "### Cost functions\n",
    "> 일반적인 머신러닝 모델과 마찬가지로 **비용함수(cost function)를 정의하고 최소화 하는 방향**으로 학습시킨다.  \n",
    "\n",
    "모델 출력값에 따른 비용함수는 아래와 같다.\n",
    "\n",
    "> **MAE**(회귀모델)\n",
    ">><img src=\"https://drive.google.com/uc?id=1RnkdTrErpOEK_pqPgrJASSpaYZMaQtII\">\n",
    "\n",
    "> **Cross entropy loss**(이진 분류)\n",
    ">><img src=\"https://drive.google.com/uc?id=1cWDiTXKPaKPMSmZ2wpPyhtUEcZml3k4i\">\n",
    "\n",
    "> **Softmax**(다중 클래스 분류)\n",
    ">><img src=\"https://drive.google.com/uc?id=1oNzYAkccbohXOEEK3gifvWP_H69AZOAs\">\n",
    "\n",
    "### 최적화(순전파)\n",
    "> 결국 cost function이 의미하고자 하는 바는 **비용함수를 최소화 시키는 가중치를 찾고싶다** 이다.\n",
    ">><img src=\"https://drive.google.com/uc?id=1vpAbQJAhkYKUG6sNmb3CgvtBdY4vyten\">\n",
    "<img src=\"https://drive.google.com/uc?id=1ImhFj4qtiYazwUb7YLjAqo38g2HHjyLO\">\n",
    "\n",
    "일반적인 머신러닝 알고리즘이 가정에 따른 비용함수 최소화를 목적으로 했다면 신경망의 최적화는 **가중치에 따른 비용함수 최소화**를 목적으로 한다.  \n",
    "즉, 학습이 진행되는 스텝마다 가중치를(그래디언트 반대방향으로)업데이트 하면서 최적값을 찾는 과정을 거친다.\n",
    "\n",
    "### 역전파(back propagation)\n",
    "> 오차에 대한 가중치를 업데이트 하기 위한 방법론으로 가중치의 변화가 최종 비용함수에 어떤 영향을 미치는지를 계산  \n",
    "chain rule을 활용 비용함수로부터 역방향으로 계산한다.\n",
    ">> w2에 대한 가중치 업데이트\n",
    "<img src=\"https://drive.google.com/uc?id=1NqlnOVAJCCDeWnk9r_5AK1x_b6Y_R62A\">\n",
    ">> w2에 대한 비용함수의 편미분 식을 ($\\hat{y}$에 대한 비용함수 편미분) X (w2에 대한 $\\hat{y}$ 편미분)의 식으로 전개\n",
    "<img src=\"https://drive.google.com/uc?id=1hOIW7EXow5gQab68QOo5HII2JAzhDg0u\">\n",
    ">> 이후 w1에 대한 가중치 업데이트도 마찬가지 방법으로 편미분 chain rule 활용한다.\n",
    "<img src=\"https://drive.google.com/uc?id=1WmhbYLibGLvxuxdLAKKREnkC9zkuedff\">\n",
    ">><img src=\"https://drive.google.com/uc?id=1itEcg3mgJWvdH0n7odwHBRbm3ieg6cB_\">\n",
    "\n",
    "### 학습률(learning rate)\n",
    "> 신경망 학습에는 학습률이 중요한데 chain rule을 통해 구해지는 업데이트 값에 학습률을 곱해 가중치를 업데이트 한다.  \n",
    "적절한 학습률은 너무 큰 업데이트값을 사용함으로서 모델 학습이 되지 않거나 너무 작은 업데이트 값을 곱해 학습이 더뎌지는 문제를 해결할 수 있다.  \n",
    "가중치 X 학습률 $\\eta$ 만큼 업데이트 하면서 최적값을 찾는 과정을 거친다.\n",
    "# $$W \\leftarrow W - \\eta{{\\partial j}(W)\\over{\\partial W}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T18:55:46.806145Z",
     "start_time": "2021-07-30T18:55:46.775052Z"
    }
   },
   "outputs": [],
   "source": [
    "# kospi 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:08:15.481261Z",
     "start_time": "2021-07-30T19:08:15.477077Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:08:17.353842Z",
     "start_time": "2021-07-30T19:08:17.348587Z"
    }
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:02:40.643682Z",
     "start_time": "2021-07-30T19:02:40.640973Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:17:31.375947Z",
     "start_time": "2021-07-30T19:17:31.371256Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "\n",
    "'''\n",
    "hidden_layer_sizes=(100,) : 히든레이어 구조(40, 40, 60) 튜플로 전달\n",
    "activation='relu': 활성함수\n",
    "learning_rate_init=0.001: 학습률\n",
    "max_iter=200 : 학습 반복 횟수\n",
    "\n",
    "데이터에 맞는 히든레이어 구조는 다 다릅니다. \n",
    "큰 데이터라도 깊이가 얕은 모델의 성능이 좋을 수 있어 파라메터 서칭이 필요합니다.\n",
    "일반적으로는 구조가 복잡해질수록 학습률을 줄이면서 반복횟수를 많이 가져가게 됩니다.\n",
    "\n",
    "이 외 파라메터는 최적화 관련 파라메터인데 현재 가장 좋은 알고리즘이 기본적으로 탑재되어 있으니 그냥 쓰시면 됩니다.\n",
    "수업시간에 모두 다루기 어렵습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:17:33.455024Z",
     "start_time": "2021-07-30T19:17:32.049576Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:17:33.665565Z",
     "start_time": "2021-07-30T19:17:33.658005Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search 실습\n",
    "복잡한 모델일수록 조절해줘야 하는 파라메터가 많이 늘어난다. 너무 많은 경우의 수가 있어 수작업으로 최적 파라메터를 찾기에는 시간적, 리소스적 비효율이 있다.  \n",
    "최적 파라메터를 자동화하여 찾을 수 있도록 sklearn 에서는 gridsearch 라는 방법론을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:26:58.520827Z",
     "start_time": "2021-07-30T19:26:58.518119Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:30:00.581954Z",
     "start_time": "2021-07-30T19:30:00.578118Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid 파라메터 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:52:36.259288Z",
     "start_time": "2021-07-30T19:52:36.254618Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid 인스턴스 설정\n",
    "\n",
    "'''\n",
    "estimator : 모델 딕셔너리\n",
    "param_grid : 파라메터 딕셔너리\n",
    "scoring=None : 평가방법\n",
    "n_jobs=None : 학습에 사용할 컴퓨터 코어 갯수\n",
    "verbose=0 : 리포트 형식 0, 1, 2\n",
    "\n",
    "scoring 참고\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:53:10.394092Z",
     "start_time": "2021-07-30T19:52:37.294090Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T19:51:33.653311Z",
     "start_time": "2021-07-30T19:51:33.648945Z"
    }
   },
   "outputs": [],
   "source": [
    "# 최고 결과 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델까지 포함한 grid search 예시\n",
    "for (model, parameter_dic) in zip([SVM_model, tree_model, NB_model, NN_model], [SVM_parameter, tree_parameter, NB_parameter, NN_parameter]):\n",
    "    grid = GridSearchCV(estimator = model, param_grid = parameter_dic, cv = 5, scoring = 'accuracy')\n",
    "    grid.fit(X, Y)\n",
    "    print(best_score)\n",
    "    if best_score < grid.best_score_:\n",
    "        best_score = grid.best_score_              \n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "print(best_model)\n",
    "print(best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
